{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "248b7e6a-a9a5-44a0-8c46-19c25d476cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image \n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "\n",
    "import skimage\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from skimage.feature import hog\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a0ec9-7253-4c12-8df7-55390b87426f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ed22e98-0a36-4589-8e55-9a3131cdd27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrayScaleConverter(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Convert an array of RGB images to grayscale\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self):\n",
    "        pass\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"returns itself\"\"\"\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"perform the transformation and return an array\"\"\"\n",
    "        return np.array([skimage.color.rgb2gray(img) for img in X])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3401d458-932b-4a6b-a0e5-697cf3d6859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HogTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Expects an array of 2d arrays (1 channel images)\n",
    "    Calculates hog features for each img\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, y=None, orientations=9,\n",
    "                 pixels_per_cell=(14,14),\n",
    "                 cells_per_block=(2,2), block_norm='L2-Hys'):\n",
    "        self.y = y\n",
    "        self.orientations = orientations\n",
    "        self.pixels_per_cell = pixels_per_cell\n",
    "        self.cells_per_block = cells_per_block\n",
    "        self.block_norm = block_norm\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    " \n",
    "        def local_hog(X):\n",
    "            return hog(X,\n",
    "                       orientations=self.orientations,\n",
    "                       pixels_per_cell=self.pixels_per_cell,\n",
    "                       cells_per_block=self.cells_per_block,\n",
    "                       block_norm=self.block_norm)\n",
    " \n",
    "        try: # parallel\n",
    "            return np.array([local_hog(img) for img in X])\n",
    "        except:\n",
    "            return np.array([local_hog(img) for img in X])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afbcd783-56d2-4aa9-9c7b-7ea11c4dd63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CannyEdgeDetector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, gaussian_kernel_size=(3, 3), gaussian_sigma=0, canny_low_threshold=100, canny_high_threshold=200):\n",
    "        self.gaussian_kernel_size = gaussian_kernel_size\n",
    "        self.gaussian_sigma = gaussian_sigma\n",
    "        self.canny_low_threshold = canny_low_threshold\n",
    "        self.canny_high_threshold = canny_high_threshold\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    "        edged_images = []\n",
    "        for image in X:\n",
    "            # Appliquer le filtre gaussien\n",
    "            blurred_image = cv2.GaussianBlur(np.uint8(image), self.gaussian_kernel_size, self.gaussian_sigma)\n",
    "            \n",
    "            # Appliquer le filtre Canny\n",
    "            edges = cv2.Canny(blurred_image, self.canny_low_threshold, self.canny_high_threshold)\n",
    "            \n",
    "            # Ajouter les bords détectés à l'image d'origine\n",
    "            edged_image = cv2.bitwise_and(image, image, mask=edges)\n",
    "            \n",
    "            edged_images.append(edged_image)\n",
    "            \n",
    "        return np.array(edged_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77e65c55-3152-46e8-99ad-9f795ee9d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaplacianFilter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, ddepth=cv2.CV_64F):\n",
    "        self.ddepth = ddepth\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    "        laplacian_images = []\n",
    "        for image in X:\n",
    "            # Appliquer le filtre Laplacien\n",
    "            laplacian_image = cv2.Laplacian(np.uint8(image), self.ddepth)\n",
    "            \n",
    "            # Convertir l'image en 3 canaux si nécessaire\n",
    "            if len(image.shape) == 3:\n",
    "                laplacian_image = cv2.cvtColor(laplacian_image, cv2.COLOR_GRAY2BGR)\n",
    "            \n",
    "            laplacian_images.append(laplacian_image)\n",
    "            \n",
    "        return np.array(laplacian_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19f15072-7054-445c-8247-8349bb507b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HSVHistogram(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, bins=256):\n",
    "        self.bins = bins\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    "        histograms = []\n",
    "        for image in X:\n",
    "            \n",
    "            # Assurez-vous que l'image est en format flottant\n",
    "            image = image.astype(np.float32)\n",
    "\n",
    "            # Normaliser l'image pour obtenir des valeurs entre 0 et 1\n",
    "            image /= 255.0\n",
    "\n",
    "            # Diviser l'image en canaux de couleur\n",
    "            channels = cv2.split(image)\n",
    "\n",
    "            # Initialiser un histogramme vide pour chaque canal de couleur\n",
    "            hist = []\n",
    "\n",
    "            # Calculer l'histogramme pour chaque canal de couleur\n",
    "            for channel in channels:\n",
    "                hist_channel, _ = np.histogram(channel, bins=256, range=(0, 1))\n",
    "                hist.append(hist_channel)\n",
    "\n",
    "            # Concaténer les histogrammes de chaque canal pour obtenir l'histogramme global\n",
    "            hist = np.concatenate(hist)\n",
    "            histograms.append(hist)\n",
    "            \n",
    "        return np.array(histograms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b221e3de-c476-4059-9fb7-7f246b0c40ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55b54e6e-10bf-457e-9173-064c46d20f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger un tableau NumPy à partir du fichier HDF5\n",
    "with h5py.File('data_0_comp_100.h5', 'r') as hf:\n",
    "    X_images_train = hf['X_images_train'][:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7672aad-259d-4aff-9317-d485ee935ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = GrayScaleConverter()\n",
    "X_train_gray = processor.transform(X_images_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9445609a-3023-4908-8333-8aebfc2fe825",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = HogTransformer()\n",
    "X_train_hog = processor.transform(X_train_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54aa3460-a364-4cc1-8976-b906dd4d8cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = CannyEdgeDetector()\n",
    "X_train_canny = processor.transform(X_train_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ecb022d-e602-4cb5-90a9-65f7357dd63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = LaplacianFilter()\n",
    "X_train_laplacian = processor.transform(X_train_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "002008c5-1127-4fcc-8dde-f4b0f9eaeb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = HSVHistogram()\n",
    "X_train_hsv = processor.transform(X_images_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "526acd97-cfd6-4e70-af4b-fb114a0a3207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouvrir le fichier HDF5 existant en mode append\n",
    "with h5py.File('data_0_comp_100.h5', 'r+') as hf:\n",
    "    # Créer un nouvel ensemble de données dans le fichier HDF5\n",
    "    hf.create_dataset('X_train_canny', data=X_train_canny, compression='gzip')\n",
    "    hf.create_dataset('X_train_laplacian', data=X_train_laplacian, compression='gzip')\n",
    "    hf.create_dataset('X_train_hog', data=X_train_hog, compression='gzip')\n",
    "    hf.create_dataset('X_train_hsv', data=X_train_hsv, compression='gzip')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abb79dd9-431c-4115-a1f1-36a8c10195e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m X_train\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m X_train_canny\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m X_train_laplacian\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "del X_train\n",
    "del X_train_canny\n",
    "del X_train_laplacian\n",
    "del X_train_hog\n",
    "del X_train_hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7500ce13-7bc0-4f75-8c7c-aae55be7bacf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040bac2d-44dd-4850-9907-18f42b240558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rakuten",
   "language": "python",
   "name": "rakuten"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
