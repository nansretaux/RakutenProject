{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "248b7e6a-a9a5-44a0-8c46-19c25d476cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image \n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "\n",
    "import skimage\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from skimage.feature import hog\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a0ec9-7253-4c12-8df7-55390b87426f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ed22e98-0a36-4589-8e55-9a3131cdd27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrayScaleConverter(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Convert an array of RGB images to grayscale\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self):\n",
    "        pass\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"returns itself\"\"\"\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"perform the transformation and return an array\"\"\"\n",
    "        return np.array([skimage.color.rgb2gray(img) for img in X])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3401d458-932b-4a6b-a0e5-697cf3d6859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HogTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Expects an array of 2d arrays (1 channel images)\n",
    "    Calculates hog features for each img\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, y=None, orientations=9,\n",
    "                 pixels_per_cell=(14,14),\n",
    "                 cells_per_block=(2,2), block_norm='L2-Hys'):\n",
    "        self.y = y\n",
    "        self.orientations = orientations\n",
    "        self.pixels_per_cell = pixels_per_cell\n",
    "        self.cells_per_block = cells_per_block\n",
    "        self.block_norm = block_norm\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    " \n",
    "        def local_hog(X):\n",
    "            return hog(X,\n",
    "                       orientations=self.orientations,\n",
    "                       pixels_per_cell=self.pixels_per_cell,\n",
    "                       cells_per_block=self.cells_per_block,\n",
    "                       block_norm=self.block_norm)\n",
    " \n",
    "        try: # parallel\n",
    "            return np.array([local_hog(img) for img in X])\n",
    "        except:\n",
    "            return np.array([local_hog(img) for img in X])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afbcd783-56d2-4aa9-9c7b-7ea11c4dd63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CannyEdgeDetector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, gaussian_kernel_size=(3, 3), gaussian_sigma=0, canny_low_threshold=100, canny_high_threshold=200):\n",
    "        self.gaussian_kernel_size = gaussian_kernel_size\n",
    "        self.gaussian_sigma = gaussian_sigma\n",
    "        self.canny_low_threshold = canny_low_threshold\n",
    "        self.canny_high_threshold = canny_high_threshold\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    "        edged_images = []\n",
    "        for image in X:\n",
    "            # Appliquer le filtre gaussien\n",
    "            blurred_image = cv2.GaussianBlur(np.uint8(image), self.gaussian_kernel_size, self.gaussian_sigma)\n",
    "            \n",
    "            # Appliquer le filtre Canny\n",
    "            edges = cv2.Canny(blurred_image, self.canny_low_threshold, self.canny_high_threshold)\n",
    "            \n",
    "            # Ajouter les bords détectés à l'image d'origine\n",
    "            edged_image = cv2.bitwise_and(image, image, mask=edges)\n",
    "            \n",
    "            edged_images.append(edged_image)\n",
    "            \n",
    "        return np.array(edged_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77e65c55-3152-46e8-99ad-9f795ee9d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaplacianFilter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, ddepth=cv2.CV_64F):\n",
    "        self.ddepth = ddepth\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    "        laplacian_images = []\n",
    "        for image in X:\n",
    "            # Appliquer le filtre Laplacien\n",
    "            laplacian_image = cv2.Laplacian(np.uint8(image), self.ddepth)\n",
    "            \n",
    "            # Convertir l'image en 3 canaux si nécessaire\n",
    "            if len(image.shape) == 3:\n",
    "                laplacian_image = cv2.cvtColor(laplacian_image, cv2.COLOR_GRAY2BGR)\n",
    "            \n",
    "            laplacian_images.append(laplacian_image)\n",
    "            \n",
    "        return np.array(laplacian_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19f15072-7054-445c-8247-8349bb507b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HSVHistogram(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, bins=256):\n",
    "        self.bins = bins\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    "        histograms = []\n",
    "        for image in X:\n",
    "            \n",
    "            # Assurez-vous que l'image est en format flottant\n",
    "            image = image.astype(np.float32)\n",
    "\n",
    "            # Normaliser l'image pour obtenir des valeurs entre 0 et 1\n",
    "            image /= 255.0\n",
    "\n",
    "            # Diviser l'image en canaux de couleur\n",
    "            channels = cv2.split(image)\n",
    "\n",
    "            # Initialiser un histogramme vide pour chaque canal de couleur\n",
    "            hist = []\n",
    "\n",
    "            # Calculer l'histogramme pour chaque canal de couleur\n",
    "            for channel in channels:\n",
    "                hist_channel, _ = np.histogram(channel, bins=256, range=(0, 1))\n",
    "                hist.append(hist_channel)\n",
    "\n",
    "            # Concaténer les histogrammes de chaque canal pour obtenir l'histogramme global\n",
    "            hist = np.concatenate(hist)\n",
    "            histograms.append(hist)\n",
    "            \n",
    "        return np.array(histograms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b221e3de-c476-4059-9fb7-7f246b0c40ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55b54e6e-10bf-457e-9173-064c46d20f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger un tableau NumPy à partir du fichier HDF5\n",
    "with h5py.File('data_0_comp_100.h5', 'r') as hf:\n",
    "    X_images_train = hf['X_images_train'][:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7672aad-259d-4aff-9317-d485ee935ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = GrayScaleConverter()\n",
    "X_train_gray = processor.transform(X_images_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9445609a-3023-4908-8333-8aebfc2fe825",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = HogTransformer()\n",
    "X_train_hog = processor.transform(X_train_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54aa3460-a364-4cc1-8976-b906dd4d8cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = CannyEdgeDetector()\n",
    "X_train_canny = processor.transform(X_train_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ecb022d-e602-4cb5-90a9-65f7357dd63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = LaplacianFilter()\n",
    "X_train_laplacian = processor.transform(X_train_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "002008c5-1127-4fcc-8dde-f4b0f9eaeb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = HSVHistogram()\n",
    "X_train_hsv = processor.transform(X_images_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "526acd97-cfd6-4e70-af4b-fb114a0a3207",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create dataset (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ouvrir le fichier HDF5 existant en mode append\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_4_comp.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m hf:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Créer un nouvel ensemble de données dans le fichier HDF5\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mhf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mX_train_canny\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_canny\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgzip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     hf\u001b[38;5;241m.\u001b[39mcreate_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_train_laplacian\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mX_train_laplacian, compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m     hf\u001b[38;5;241m.\u001b[39mcreate_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_train_hog\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mX_train_hog, compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rakuten\\lib\\site-packages\\h5py\\_hl\\group.py:183\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[1;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[0;32m    180\u001b[0m         parent_path, name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    181\u001b[0m         group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_group(parent_path)\n\u001b[1;32m--> 183\u001b[0m dsid \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmake_new_dset(group, shape, dtype, data, name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    184\u001b[0m dset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mDataset(dsid)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dset\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rakuten\\lib\\site-packages\\h5py\\_hl\\dataset.py:163\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[1;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     sid \u001b[38;5;241m=\u001b[39m h5s\u001b[38;5;241m.\u001b[39mcreate_simple(shape, maxshape)\n\u001b[1;32m--> 163\u001b[0m dset_id \u001b[38;5;241m=\u001b[39m \u001b[43mh5d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdcpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Empty)):\n\u001b[0;32m    166\u001b[0m     dset_id\u001b[38;5;241m.\u001b[39mwrite(h5s\u001b[38;5;241m.\u001b[39mALL, h5s\u001b[38;5;241m.\u001b[39mALL, data)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5d.pyx:138\u001b[0m, in \u001b[0;36mh5py.h5d.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to create dataset (name already exists)"
     ]
    }
   ],
   "source": [
    "# Ouvrir le fichier HDF5 existant en mode append\n",
    "with h5py.File('data_4_comp.h5', 'r+') as hf:\n",
    "    # Créer un nouvel ensemble de données dans le fichier HDF5\n",
    "    hf.create_dataset('X_train_canny', data=X_train_canny, compression='gzip')\n",
    "    hf.create_dataset('X_train_laplacian', data=X_train_laplacian, compression='gzip')\n",
    "    hf.create_dataset('X_train_hog', data=X_train_hog, compression='gzip')\n",
    "    hf.create_dataset('X_train_hsv', data=X_train_hsv, compression='gzip')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb79dd9-431c-4115-a1f1-36a8c10195e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train\n",
    "del X_train_canny\n",
    "del X_train_laplacian\n",
    "del X_train_hog\n",
    "del X_train_hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7500ce13-7bc0-4f75-8c7c-aae55be7bacf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040bac2d-44dd-4850-9907-18f42b240558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rakuten",
   "language": "python",
   "name": "rakuten"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
