{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "248b7e6a-a9a5-44a0-8c46-19c25d476cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image \n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "\n",
    "import skimage\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from skimage.feature import hog\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e31a0ec9-7253-4c12-8df7-55390b87426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chemin des images\n",
    "folder_path = 'C:/Users/Nans/OneDrive/Documents/Rakuten Project/images/images/image_train'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d94bebe-049c-446d-a822-2d798501f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_cropping(img):\n",
    "\n",
    "    largeur_fixe = 224\n",
    "    hauteur_fixe = 224\n",
    "    \n",
    "    # Convertir l'image en niveaux de gris\n",
    "    image_gris = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Inverser les niveaux de gris\n",
    "    image_inversee = cv2.bitwise_not(image_gris)\n",
    "\n",
    "    # Trouver les contours dans l'image\n",
    "    contours, hierarchy = cv2.findContours(image_inversee, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        \n",
    "        # Trouver le contour le plus externe\n",
    "        contour_externe = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Trouver les coordonnées du rectangle englobant le contour externe\n",
    "        x, y, w, h = cv2.boundingRect(contour_externe)\n",
    "\n",
    "        # Rogner l'image en utilisant les coordonnées du rectangle englobant\n",
    "        cropped_image = img[y:y+h, x:x+w]\n",
    "\n",
    "        cropped_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Redimensionner l'image pour qu'elle ait la même taille que les autres\n",
    "        cropped_image_resized = cv2.resize(cropped_image, (largeur_fixe, hauteur_fixe))\n",
    "\n",
    "        return np.array(cropped_image_resized)\n",
    "\n",
    "    else:\n",
    "        # Si aucun contour n'est trouvé, retourner None\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f2d3445-d5a7-4335-9aff-d5d78568fc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Obtenez la liste des fichiers dans le dossier\n",
    "img_in_folder = os.listdir(folder_path)\n",
    "\n",
    "# Parcourez chaque fichier dans le dossier\n",
    "batch_size = 10000\n",
    "num_batches = len(img_in_folder) // batch_size + 1\n",
    "#num_batches = 2\n",
    "\n",
    "for batch_idx in range(num_batches):\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = min((batch_idx + 1) * batch_size, len(img_in_folder))\n",
    "    \n",
    "    batch_files = img_in_folder[start_idx:end_idx]\n",
    "\n",
    "    # Initialisez des listes pour stocker les identifiants des images et des produits\n",
    "    image_ids = []\n",
    "    product_ids = []\n",
    "    image_vectors = []  \n",
    "    \n",
    "    # Traitement du lot d'images\n",
    "    for img in batch_files:\n",
    "\n",
    "        # Utilisez une expression régulière pour extraire les identifiants d'image et de produit\n",
    "        match = re.match(r'image_(\\d+)_product_(\\d+)\\.jpg', img)\n",
    "        if match:\n",
    "            image_id = match.group(1)\n",
    "            product_id = match.group(2)\n",
    "        \n",
    "            # Lire l'image avec OpenCV\n",
    "            img_path = os.path.join(folder_path, img)\n",
    "            image = cv2.imread(img_path)\n",
    "\n",
    "            # Fonction d'image cropping\n",
    "            cropped_img = img_cropping(image)\n",
    "        \n",
    "            # Assurez-vous que l'image existe\n",
    "            if cropped_img is not None:           \n",
    "                # Ajoutez les identifiants et le vecteur d'image à leurs listes respectives\n",
    "                image_ids.append(int(image_id))\n",
    "                product_ids.append(int(product_id))\n",
    "                image_vectors.append(cropped_img)\n",
    "            \n",
    "    # Convertir les listes en tableaux NumPy\n",
    "    image_vectors = np.array(image_vectors)\n",
    "    image_ids = np.array(image_ids)\n",
    "    product_ids = np.array(product_ids)\n",
    "\n",
    "\n",
    "    # Créer un fichier HDF5 et y enregistrer un tableau NumPy\n",
    "    with h5py.File('data_' + str(batch_idx) + 'comp.h5', 'w') as hf:\n",
    "        hf.create_dataset('X_train', data=image_vectors, compression='gzip')\n",
    "        hf.create_dataset('image_ids', data=image_ids, compression='gzip')\n",
    "        hf.create_dataset('product_ids', data=product_ids, compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22ec26a6-c68b-4d13-b206-6d7fa522384a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a89aca-0327-4b0c-a88f-b29f1d44822c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rakuten",
   "language": "python",
   "name": "rakuten"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
