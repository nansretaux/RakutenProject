{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "248b7e6a-a9a5-44a0-8c46-19c25d476cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image \n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "\n",
    "import skimage\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from skimage.feature import hog\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e31a0ec9-7253-4c12-8df7-55390b87426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chemin des images\n",
    "folder_path = 'C:/Users/Nans/OneDrive/Documents/Rakuten Project/images/images/image_train'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d94bebe-049c-446d-a822-2d798501f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_cropping(img):\n",
    "\n",
    "    largeur_fixe = 100\n",
    "    hauteur_fixe = 100\n",
    "    \n",
    "    # Convertir l'image en niveaux de gris\n",
    "    image_gris = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Inverser les niveaux de gris\n",
    "    image_inversee = cv2.bitwise_not(image_gris)\n",
    "\n",
    "    # Trouver les contours dans l'image\n",
    "    contours, hierarchy = cv2.findContours(image_inversee, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        \n",
    "        # Trouver le contour le plus externe\n",
    "        contour_externe = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Trouver les coordonnées du rectangle englobant le contour externe\n",
    "        x, y, w, h = cv2.boundingRect(contour_externe)\n",
    "\n",
    "        # Rogner l'image en utilisant les coordonnées du rectangle englobant\n",
    "        cropped_image = img[y:y+h, x:x+w]\n",
    "\n",
    "        cropped_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Redimensionner l'image pour qu'elle ait la même taille que les autres\n",
    "        cropped_image_resized = cv2.resize(cropped_image, (largeur_fixe, hauteur_fixe))\n",
    "\n",
    "        return np.array(cropped_image_resized)\n",
    "\n",
    "    else:\n",
    "        # Si aucun contour n'est trouvé, retourner None\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f2d3445-d5a7-4335-9aff-d5d78568fc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Obtenez la liste des fichiers dans le dossier\n",
    "img_in_folder = os.listdir(folder_path)\n",
    "\n",
    "# Parcourez chaque fichier dans le dossier\n",
    "batch_size = 10000\n",
    "num_batches = len(img_in_folder) // batch_size + 1\n",
    "#num_batches = 2\n",
    "\n",
    "for batch_idx in range(num_batches):\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = min((batch_idx + 1) * batch_size, len(img_in_folder))\n",
    "    \n",
    "    batch_files = img_in_folder[start_idx:end_idx]\n",
    "\n",
    "    # Initialisez des listes pour stocker les identifiants des images et des produits\n",
    "    image_ids = []\n",
    "    product_ids = []\n",
    "    image_vectors = []  \n",
    "    \n",
    "    # Traitement du lot d'images\n",
    "    for img in batch_files:\n",
    "\n",
    "        # Utilisez une expression régulière pour extraire les identifiants d'image et de produit\n",
    "        match = re.match(r'image_(\\d+)_product_(\\d+)\\.jpg', img)\n",
    "        if match:\n",
    "            image_id = match.group(1)\n",
    "            product_id = match.group(2)\n",
    "        \n",
    "            # Lire l'image avec OpenCV\n",
    "            img_path = os.path.join(folder_path, img)\n",
    "            image = cv2.imread(img_path)\n",
    "\n",
    "            # Fonction d'image cropping\n",
    "            cropped_img = img_cropping(image)\n",
    "        \n",
    "            # Assurez-vous que l'image existe\n",
    "            if cropped_img is not None:           \n",
    "                # Ajoutez les identifiants et le vecteur d'image à leurs listes respectives\n",
    "                image_ids.append(int(image_id))\n",
    "                product_ids.append(int(product_id))\n",
    "                image_vectors.append(cropped_img)\n",
    "            \n",
    "    # Convertir les listes en tableaux NumPy\n",
    "    image_vectors = np.array(image_vectors)\n",
    "    image_ids = np.array(image_ids)\n",
    "    product_ids = np.array(product_ids)\n",
    "\n",
    "\n",
    "    # Créer un fichier HDF5 et y enregistrer un tableau NumPy\n",
    "    with h5py.File('data_' + str(batch_idx) + 'comp_100.h5', 'w') as hf:\n",
    "        hf.create_dataset('X_images_train', data=image_vectors, compression='gzip')\n",
    "        hf.create_dataset('image_ids', data=image_ids, compression='gzip')\n",
    "        hf.create_dataset('product_ids', data=product_ids, compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a89aca-0327-4b0c-a88f-b29f1d44822c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b1e936-cb3a-410f-b39b-bcda6b1d8c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abbeedd2-9a3f-4be0-ab45-de86ad96f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrayScaleConverter(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Convert an array of RGB images to grayscale\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self):\n",
    "        pass\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"returns itself\"\"\"\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"perform the transformation and return an array\"\"\"\n",
    "        return np.array([skimage.color.rgb2gray(img) for img in X])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f44b0baf-9423-45ec-a307-a41d33eef67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HogTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Expects an array of 2d arrays (1 channel images)\n",
    "    Calculates hog features for each img\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, y=None, orientations=9,\n",
    "                 pixels_per_cell=(14,14),\n",
    "                 cells_per_block=(2,2), block_norm='L2-Hys'):\n",
    "        self.y = y\n",
    "        self.orientations = orientations\n",
    "        self.pixels_per_cell = pixels_per_cell\n",
    "        self.cells_per_block = cells_per_block\n",
    "        self.block_norm = block_norm\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    " \n",
    "        def local_hog(X):\n",
    "            return hog(X,\n",
    "                       orientations=self.orientations,\n",
    "                       pixels_per_cell=self.pixels_per_cell,\n",
    "                       cells_per_block=self.cells_per_block,\n",
    "                       block_norm=self.block_norm)\n",
    " \n",
    "        try: # parallel\n",
    "            return np.array([local_hog(img) for img in X])\n",
    "        except:\n",
    "            return np.array([local_hog(img) for img in X])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f84d0694-a595-4f84-b2fa-970d39072048",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CannyEdgeDetector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, gaussian_kernel_size=(3, 3), gaussian_sigma=0, canny_low_threshold=100, canny_high_threshold=200):\n",
    "        self.gaussian_kernel_size = gaussian_kernel_size\n",
    "        self.gaussian_sigma = gaussian_sigma\n",
    "        self.canny_low_threshold = canny_low_threshold\n",
    "        self.canny_high_threshold = canny_high_threshold\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    "        edged_images = []\n",
    "        for image in X:\n",
    "            # Appliquer le filtre gaussien\n",
    "            blurred_image = cv2.GaussianBlur(np.uint8(image), self.gaussian_kernel_size, self.gaussian_sigma)\n",
    "            \n",
    "            # Appliquer le filtre Canny\n",
    "            edges = cv2.Canny(blurred_image, self.canny_low_threshold, self.canny_high_threshold)\n",
    "            \n",
    "            # Ajouter les bords détectés à l'image d'origine\n",
    "            edged_image = cv2.bitwise_and(image, image, mask=edges)\n",
    "            \n",
    "            edged_images.append(edged_image)\n",
    "            \n",
    "        return np.array(edged_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f666c16c-9cf0-4fae-ac67-4726ba55e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaplacianFilter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, ddepth=cv2.CV_64F):\n",
    "        self.ddepth = ddepth\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    "        laplacian_images = []\n",
    "        for image in X:\n",
    "            # Appliquer le filtre Laplacien\n",
    "            laplacian_image = cv2.Laplacian(np.uint8(image), self.ddepth)\n",
    "            \n",
    "            # Convertir l'image en 3 canaux si nécessaire\n",
    "            if len(image.shape) == 3:\n",
    "                laplacian_image = cv2.cvtColor(laplacian_image, cv2.COLOR_GRAY2BGR)\n",
    "            \n",
    "            laplacian_images.append(laplacian_image)\n",
    "            \n",
    "        return np.array(laplacian_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93a064e5-54b7-4200-85fb-a91e84fa924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HSVHistogram(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, bins=256):\n",
    "        self.bins = bins\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    "        histograms = []\n",
    "        for image in X:\n",
    "            \n",
    "            # Assurez-vous que l'image est en format flottant\n",
    "            image = image.astype(np.float32)\n",
    "\n",
    "            # Normaliser l'image pour obtenir des valeurs entre 0 et 1\n",
    "            image /= 255.0\n",
    "\n",
    "            # Diviser l'image en canaux de couleur\n",
    "            channels = cv2.split(image)\n",
    "\n",
    "            # Initialiser un histogramme vide pour chaque canal de couleur\n",
    "            hist = []\n",
    "\n",
    "            # Calculer l'histogramme pour chaque canal de couleur\n",
    "            for channel in channels:\n",
    "                hist_channel, _ = np.histogram(channel, bins=256, range=(0, 1))\n",
    "                hist.append(hist_channel)\n",
    "\n",
    "            # Concaténer les histogrammes de chaque canal pour obtenir l'histogramme global\n",
    "            hist = np.concatenate(hist)\n",
    "            histograms.append(hist)\n",
    "            \n",
    "        return np.array(histograms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f728213b-ff7a-4369-ba62-dec986b89071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger un tableau NumPy à partir du fichier HDF5\n",
    "with h5py.File('data_0_comp_100.h5', 'r') as hf:\n",
    "    X_images_train = hf['X_images_train'][:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0610d329-7832-436c-8208-e19bd309691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = GrayScaleConverter()\n",
    "X_train_gray = processor.transform(X_images_train)\n",
    "\n",
    "processor = HogTransformer()\n",
    "X_train_hog = processor.transform(X_train_gray)\n",
    "\n",
    "processor = CannyEdgeDetector()\n",
    "X_train_canny = processor.transform(X_train_gray)\n",
    "\n",
    "processor = LaplacianFilter()\n",
    "X_train_laplacian = processor.transform(X_train_gray)\n",
    "\n",
    "processor = HSVHistogram()\n",
    "X_train_hsv = processor.transform(X_images_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f5cfdd-ee2a-4aed-ad01-ab3573202a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouvrir le fichier HDF5 existant en mode append\n",
    "with h5py.File('data_0_comp_100.h5', 'r+') as hf:\n",
    "    # Créer un nouvel ensemble de données dans le fichier HDF5\n",
    "    hf.create_dataset('X_train_canny', data=X_train_canny, compression='gzip')\n",
    "    hf.create_dataset('X_train_laplacian', data=X_train_laplacian, compression='gzip')\n",
    "    hf.create_dataset('X_train_hog', data=X_train_hog, compression='gzip')\n",
    "    hf.create_dataset('X_train_hsv', data=X_train_hsv, compression='gzip')\n",
    "    hf.create_dataset('X_train_gray', data=X_train_gray, compression='gzip')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31310f3-2286-435b-b793-3f94c8a56670",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_images_train\n",
    "del X_train_gray\n",
    "del X_train_canny\n",
    "del X_train_laplacian\n",
    "del X_train_hog\n",
    "del X_train_hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f32bbb-7a8f-4990-95fb-e0f75bdb663f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5701986a-ddf5-4214-8cb7-ac9b95dee92b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rakuten",
   "language": "python",
   "name": "rakuten"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
